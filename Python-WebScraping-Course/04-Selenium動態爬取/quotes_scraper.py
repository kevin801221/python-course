"""
å‹•æ…‹ç¶²é çˆ¬èŸ² - Quotes to Scrape (JavaScriptç‰ˆ)
==============================================
é€™æ˜¯ä¸€å€‹ä½¿ç”¨ Selenium çš„å®Œæ•´å‹•æ…‹ç¶²é çˆ¬èŸ²æ‡‰ç”¨ç¨‹å¼ã€‚
ä½¿ç”¨ http://quotes.toscrape.com/js/ ä½œç‚ºç·´ç¿’ç¶²ç«™ï¼ˆJavaScript æ¸²æŸ“ç‰ˆæœ¬ï¼‰ã€‚

åŠŸèƒ½ï¼š
1. è™•ç† JavaScript æ¸²æŸ“çš„é é¢
2. æ¨¡æ“¬ä½¿ç”¨è€…è¡Œç‚ºï¼ˆé»æ“Šã€æ»¾å‹•ï¼‰
3. è™•ç†ç„¡é™æ»¾å‹•é é¢
4. è‡ªå‹•ç™»å…¥ç¤ºç¯„
5. æˆªåœ–åŠŸèƒ½

ä½¿ç”¨æ–¹æ³•ï¼š
    python quotes_scraper.py

éœ€è¦å®‰è£ï¼š
    uv pip install selenium webdriver-manager
"""

from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException, NoSuchElementException
from dataclasses import dataclass, asdict
from typing import Optional
import json
import csv
import time
import random
from datetime import datetime


@dataclass
class Quote:
    """åè¨€è³‡æ–™çµæ§‹"""
    text: str
    author: str
    author_url: str
    tags: list
    scraped_at: str = ""


@dataclass
class Author:
    """ä½œè€…è³‡æ–™çµæ§‹"""
    name: str
    born_date: str
    born_location: str
    description: str
    url: str


class DynamicQuotesScraper:
    """å‹•æ…‹åè¨€ç¶²ç«™çˆ¬èŸ²"""

    BASE_URL = "http://quotes.toscrape.com"
    JS_URL = "http://quotes.toscrape.com/js/"
    SCROLL_URL = "http://quotes.toscrape.com/scroll"

    def __init__(self, headless: bool = True):
        self.headless = headless
        self.driver: Optional[webdriver.Chrome] = None
        self.quotes: list[Quote] = []
        self.authors: dict[str, Author] = {}

    def _setup_driver(self):
        """è¨­å®šä¸¦å•Ÿå‹• Chrome ç€è¦½å™¨"""
        options = Options()

        if self.headless:
            options.add_argument('--headless=new')

        # åŸºæœ¬è¨­å®š
        options.add_argument('--window-size=1920,1080')
        options.add_argument('--disable-gpu')
        options.add_argument('--no-sandbox')
        options.add_argument('--disable-dev-shm-usage')

        # æ¨¡æ“¬çœŸå¯¦ç€è¦½å™¨
        options.add_argument('--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36')
        options.add_argument('--disable-blink-features=AutomationControlled')
        options.add_experimental_option('excludeSwitches', ['enable-automation'])
        options.add_experimental_option('useAutomationExtension', False)

        # åœç”¨åœ–ç‰‡ä»¥åŠ é€Ÿï¼ˆå¯é¸ï¼‰
        # prefs = {'profile.managed_default_content_settings.images': 2}
        # options.add_experimental_option('prefs', prefs)

        self.driver = webdriver.Chrome(options=options)

        # è¨­å®šéš±å¼ç­‰å¾…
        self.driver.implicitly_wait(10)

        # éš±è— webdriver æ¨™èªŒ
        self.driver.execute_cdp_cmd('Page.addScriptToEvaluateOnNewDocument', {
            'source': '''
                Object.defineProperty(navigator, 'webdriver', {
                    get: () => undefined
                })
            '''
        })

    def _random_sleep(self, min_sec: float = 0.5, max_sec: float = 2.0):
        """éš¨æ©Ÿå»¶é²ï¼Œæ¨¡æ“¬äººé¡è¡Œç‚º"""
        time.sleep(random.uniform(min_sec, max_sec))

    def _scroll_to_bottom(self):
        """æ»¾å‹•åˆ°é é¢åº•éƒ¨"""
        self.driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
        self._random_sleep(1, 2)

    def _scroll_to_element(self, element):
        """æ»¾å‹•åˆ°ç‰¹å®šå…ƒç´ """
        self.driver.execute_script("arguments[0].scrollIntoView({behavior: 'smooth'});", element)
        self._random_sleep(0.5, 1)

    def scrape_js_page(self, pages: int = 3) -> list[Quote]:
        """çˆ¬å– JavaScript æ¸²æŸ“çš„é é¢"""
        print("\n" + "=" * 60)
        print("ğŸš€ é–‹å§‹çˆ¬å– JavaScript æ¸²æŸ“é é¢")
        print("=" * 60)

        try:
            self._setup_driver()

            for page in range(1, pages + 1):
                url = f"{self.JS_URL}page/{page}/" if page > 1 else self.JS_URL
                print(f"\nğŸ“„ æ­£åœ¨è™•ç†ç¬¬ {page} é : {url}")

                self.driver.get(url)

                # ç­‰å¾…åè¨€è¼‰å…¥
                try:
                    WebDriverWait(self.driver, 10).until(
                        EC.presence_of_element_located((By.CLASS_NAME, "quote"))
                    )
                except TimeoutException:
                    print(f"  âš ï¸ ç¬¬ {page} é è¼‰å…¥è¶…æ™‚")
                    continue

                # æ¨¡æ“¬æ»¾å‹•
                self._scroll_to_bottom()

                # æ“·å–åè¨€
                quote_elements = self.driver.find_elements(By.CLASS_NAME, "quote")
                print(f"  æ‰¾åˆ° {len(quote_elements)} æ¢åè¨€")

                for elem in quote_elements:
                    try:
                        text_elem = elem.find_element(By.CLASS_NAME, "text")
                        author_elem = elem.find_element(By.CLASS_NAME, "author")
                        author_link = elem.find_element(By.CSS_SELECTOR, "a[href*='author']")
                        tag_elems = elem.find_elements(By.CLASS_NAME, "tag")

                        quote = Quote(
                            text=text_elem.text.strip('""'),
                            author=author_elem.text,
                            author_url=author_link.get_attribute('href'),
                            tags=[t.text for t in tag_elems],
                            scraped_at=datetime.now().isoformat()
                        )
                        self.quotes.append(quote)

                    except NoSuchElementException as e:
                        print(f"  âš ï¸ è§£æåè¨€å¤±æ•—: {e}")
                        continue

                print(f"  âœ“ å·²æ“·å– {len(self.quotes)} æ¢åè¨€")

                # æˆªåœ–
                screenshot_path = f"page_{page}_screenshot.png"
                self.driver.save_screenshot(screenshot_path)
                print(f"  ğŸ“¸ å·²å„²å­˜æˆªåœ–: {screenshot_path}")

        finally:
            if self.driver:
                self.driver.quit()

        return self.quotes

    def scrape_infinite_scroll(self, max_scrolls: int = 5) -> list[Quote]:
        """çˆ¬å–ç„¡é™æ»¾å‹•é é¢"""
        print("\n" + "=" * 60)
        print("ğŸš€ é–‹å§‹çˆ¬å–ç„¡é™æ»¾å‹•é é¢")
        print("=" * 60)

        try:
            self._setup_driver()
            self.driver.get(self.SCROLL_URL)

            # ç­‰å¾…åˆå§‹å…§å®¹è¼‰å…¥
            WebDriverWait(self.driver, 10).until(
                EC.presence_of_element_located((By.CLASS_NAME, "quote"))
            )

            last_height = self.driver.execute_script("return document.body.scrollHeight")
            scroll_count = 0

            while scroll_count < max_scrolls:
                print(f"\nğŸ”„ ç¬¬ {scroll_count + 1} æ¬¡æ»¾å‹•...")

                # æ»¾å‹•åˆ°åº•éƒ¨
                self.driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
                self._random_sleep(2, 3)

                # æª¢æŸ¥æ˜¯å¦æœ‰æ–°å…§å®¹è¼‰å…¥
                new_height = self.driver.execute_script("return document.body.scrollHeight")

                if new_height == last_height:
                    print("  å·²åˆ°é”é é¢åº•éƒ¨")
                    break

                last_height = new_height
                scroll_count += 1

                # æ“·å–ç•¶å‰é é¢çš„åè¨€
                current_quotes = len(self.driver.find_elements(By.CLASS_NAME, "quote"))
                print(f"  ç›®å‰è¼‰å…¥ {current_quotes} æ¢åè¨€")

            # æ“·å–æ‰€æœ‰åè¨€
            print("\nğŸ“ æ­£åœ¨æ“·å–æ‰€æœ‰åè¨€...")
            quote_elements = self.driver.find_elements(By.CLASS_NAME, "quote")

            for elem in quote_elements:
                try:
                    text_elem = elem.find_element(By.CLASS_NAME, "text")
                    author_elem = elem.find_element(By.CLASS_NAME, "author")
                    tag_elems = elem.find_elements(By.CLASS_NAME, "tag")

                    quote = Quote(
                        text=text_elem.text.strip('""'),
                        author=author_elem.text,
                        author_url="",
                        tags=[t.text for t in tag_elems],
                        scraped_at=datetime.now().isoformat()
                    )
                    self.quotes.append(quote)

                except NoSuchElementException:
                    continue

            print(f"âœ… å…±æ“·å– {len(self.quotes)} æ¢åè¨€")

        finally:
            if self.driver:
                self.driver.quit()

        return self.quotes

    def demo_login(self):
        """ç¤ºç¯„è‡ªå‹•ç™»å…¥åŠŸèƒ½"""
        print("\n" + "=" * 60)
        print("ğŸ” ç¤ºç¯„è‡ªå‹•ç™»å…¥åŠŸèƒ½")
        print("=" * 60)

        try:
            self._setup_driver()

            # å‰å¾€ç™»å…¥é é¢
            login_url = f"{self.BASE_URL}/login"
            print(f"\næ­£åœ¨å‰å¾€ç™»å…¥é é¢: {login_url}")
            self.driver.get(login_url)

            self._random_sleep(1, 2)

            # æ‰¾åˆ°è¼¸å…¥æ¡†
            username_input = self.driver.find_element(By.CSS_SELECTOR, "input[name='username']")
            password_input = self.driver.find_element(By.CSS_SELECTOR, "input[name='password']")
            submit_button = self.driver.find_element(By.CSS_SELECTOR, "input[type='submit']")

            # æ¨¡æ“¬äººé¡è¼¸å…¥ï¼ˆé€å­—è¼¸å…¥ï¼‰
            print("æ­£åœ¨è¼¸å…¥å¸³è™Ÿ...")
            for char in "testuser":
                username_input.send_keys(char)
                time.sleep(random.uniform(0.05, 0.15))

            self._random_sleep(0.5, 1)

            print("æ­£åœ¨è¼¸å…¥å¯†ç¢¼...")
            for char in "testpass":
                password_input.send_keys(char)
                time.sleep(random.uniform(0.05, 0.15))

            self._random_sleep(0.5, 1)

            # æˆªåœ–ï¼ˆç™»å…¥å‰ï¼‰
            self.driver.save_screenshot("login_before.png")
            print("ğŸ“¸ å·²å„²å­˜ç™»å…¥å‰æˆªåœ–: login_before.png")

            # é»æ“Šç™»å…¥æŒ‰éˆ•
            print("æ­£åœ¨é»æ“Šç™»å…¥æŒ‰éˆ•...")
            submit_button.click()

            self._random_sleep(2, 3)

            # æª¢æŸ¥æ˜¯å¦ç™»å…¥æˆåŠŸ
            try:
                logout_link = self.driver.find_element(By.CSS_SELECTOR, "a[href='/logout']")
                print("âœ… ç™»å…¥æˆåŠŸ!")

                # æˆªåœ–ï¼ˆç™»å…¥å¾Œï¼‰
                self.driver.save_screenshot("login_after.png")
                print("ğŸ“¸ å·²å„²å­˜ç™»å…¥å¾Œæˆªåœ–: login_after.png")

            except NoSuchElementException:
                print("âŒ ç™»å…¥å¤±æ•—")

                # æª¢æŸ¥éŒ¯èª¤è¨Šæ¯
                try:
                    error = self.driver.find_element(By.CLASS_NAME, "error")
                    print(f"éŒ¯èª¤è¨Šæ¯: {error.text}")
                except NoSuchElementException:
                    pass

        finally:
            if self.driver:
                self.driver.quit()

    def scrape_author_details(self, author_url: str) -> Optional[Author]:
        """çˆ¬å–ä½œè€…è©³ç´°è³‡è¨Š"""
        try:
            self.driver.get(author_url)

            WebDriverWait(self.driver, 10).until(
                EC.presence_of_element_located((By.CLASS_NAME, "author-details"))
            )

            name = self.driver.find_element(By.CLASS_NAME, "author-title").text
            born_date = self.driver.find_element(By.CLASS_NAME, "author-born-date").text
            born_location = self.driver.find_element(By.CLASS_NAME, "author-born-location").text
            description = self.driver.find_element(By.CLASS_NAME, "author-description").text

            return Author(
                name=name,
                born_date=born_date,
                born_location=born_location.replace('in ', ''),
                description=description[:500],
                url=author_url
            )

        except Exception as e:
            print(f"  âš ï¸ æ“·å–ä½œè€…è³‡è¨Šå¤±æ•—: {e}")
            return None

    def analyze(self):
        """åˆ†æçˆ¬å–çš„è³‡æ–™"""
        if not self.quotes:
            print("âŒ æ²’æœ‰è³‡æ–™å¯åˆ†æ")
            return

        print("\n" + "=" * 60)
        print("ğŸ“Š è³‡æ–™åˆ†æ")
        print("=" * 60)

        # ä½œè€…çµ±è¨ˆ
        from collections import Counter
        author_counts = Counter(q.author for q in self.quotes)

        print(f"\nğŸ“ˆ åŸºæœ¬çµ±è¨ˆ:")
        print(f"  ç¸½åè¨€æ•¸é‡: {len(self.quotes)}")
        print(f"  ä¸åŒä½œè€…æ•¸: {len(author_counts)}")

        print(f"\nğŸ‘¤ æœ€å¤šåè¨€çš„ä½œè€…:")
        for author, count in author_counts.most_common(5):
            print(f"  {author}: {count} æ¢")

        # æ¨™ç±¤çµ±è¨ˆ
        all_tags = []
        for q in self.quotes:
            all_tags.extend(q.tags)
        tag_counts = Counter(all_tags)

        print(f"\nğŸ·ï¸ æœ€ç†±é–€çš„æ¨™ç±¤:")
        for tag, count in tag_counts.most_common(10):
            print(f"  #{tag}: {count} æ¬¡")

        # åè¨€é•·åº¦åˆ†æ
        lengths = [len(q.text) for q in self.quotes]
        print(f"\nğŸ“ åè¨€é•·åº¦åˆ†æ:")
        print(f"  æœ€çŸ­: {min(lengths)} å­—å…ƒ")
        print(f"  æœ€é•·: {max(lengths)} å­—å…ƒ")
        print(f"  å¹³å‡: {sum(lengths)//len(lengths)} å­—å…ƒ")

    def export_json(self, filename: str = "quotes_data.json"):
        """åŒ¯å‡ºç‚º JSON"""
        data = {
            'quotes': [asdict(q) for q in self.quotes],
            'total': len(self.quotes),
            'exported_at': datetime.now().isoformat()
        }
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        print(f"âœ… å·²åŒ¯å‡ºåˆ°: {filename}")

    def export_csv(self, filename: str = "quotes_data.csv"):
        """åŒ¯å‡ºç‚º CSV"""
        if not self.quotes:
            return

        with open(filename, 'w', newline='', encoding='utf-8') as f:
            fieldnames = ['text', 'author', 'author_url', 'tags', 'scraped_at']
            writer = csv.DictWriter(f, fieldnames=fieldnames)
            writer.writeheader()
            for quote in self.quotes:
                row = asdict(quote)
                row['tags'] = ', '.join(row['tags'])
                writer.writerow(row)

        print(f"âœ… å·²åŒ¯å‡ºåˆ°: {filename}")


def main():
    """ä¸»ç¨‹å¼"""
    print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘           å‹•æ…‹ç¶²é çˆ¬èŸ² - Quotes to Scrape                     â•‘
â•‘              Selenium å®Œæ•´æ‡‰ç”¨ç¯„ä¾‹                            â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)

    # é¸æ“‡æ¨¡å¼
    print("è«‹é¸æ“‡çˆ¬å–æ¨¡å¼:")
    print("1. çˆ¬å– JavaScript æ¸²æŸ“é é¢")
    print("2. çˆ¬å–ç„¡é™æ»¾å‹•é é¢")
    print("3. ç¤ºç¯„è‡ªå‹•ç™»å…¥")
    print("4. å®Œæ•´æ¸¬è©¦ï¼ˆå…¨éƒ¨åŸ·è¡Œï¼‰")

    choice = input("\nè«‹é¸æ“‡ (1-4): ").strip()

    # æ˜¯å¦ä½¿ç”¨ç„¡é ­æ¨¡å¼
    headless_input = input("ä½¿ç”¨ç„¡é ­æ¨¡å¼? (y/n, é è¨­ y): ").strip().lower()
    headless = headless_input != 'n'

    scraper = DynamicQuotesScraper(headless=headless)

    if choice == '1':
        pages = input("è¦çˆ¬å–å¹¾é ? (é è¨­ 3): ").strip()
        pages = int(pages) if pages.isdigit() else 3
        scraper.scrape_js_page(pages=pages)

    elif choice == '2':
        scrolls = input("æœ€å¤šæ»¾å‹•å¹¾æ¬¡? (é è¨­ 5): ").strip()
        scrolls = int(scrolls) if scrolls.isdigit() else 5
        scraper.scrape_infinite_scroll(max_scrolls=scrolls)

    elif choice == '3':
        scraper.demo_login()
        return  # ç™»å…¥ç¤ºç¯„ä¸éœ€è¦åŒ¯å‡º

    elif choice == '4':
        print("\n--- JavaScript æ¸²æŸ“é é¢ ---")
        scraper.scrape_js_page(pages=2)

        print("\n--- ç„¡é™æ»¾å‹•é é¢ ---")
        scraper.scrape_infinite_scroll(max_scrolls=3)

    else:
        print("ç„¡æ•ˆé¸æ“‡")
        return

    # åˆ†æèˆ‡åŒ¯å‡º
    if scraper.quotes:
        scraper.analyze()

        print("\n" + "=" * 60)
        export = input("æ˜¯å¦åŒ¯å‡ºè³‡æ–™? (y/n): ").strip().lower()
        if export == 'y':
            scraper.export_json()
            scraper.export_csv()

    print("\nğŸ‰ å®Œæˆ!")


if __name__ == "__main__":
    main()
